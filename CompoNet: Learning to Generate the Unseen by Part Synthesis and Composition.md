# CompoNet: Learning to Generate the Unseen by Part Synthesis and Composition

## Summary

## Research Objective
- How to enable a generative model to go beyond the observed observed samples and learn to generate "unseen".
## Background and Problems
- Existing generative models are always trapped or bounded by the empirical distribution of the observed data.
## Methods
- The proposed CompoNet is applied both on 2D and 3D shape. At training time, every shape is pre-segmented to its semantic parts.
- Part synthesis unit.
	- Training an individual VAE for each semantic part.
	- The encoders are fixed during the training of part composition unit.
- Parts composition unit.
	- Codes generated by encoders are fed into a composition network which learns to produce transformation parameters per part.
	- For 2D shape, the network takes in (10x4+8)-dim vector, and outputs a 16-dim vector, four values per part.
	- For 3D shape, the network takes in (64x4+16)-dim vector, and outputs a 24-dim vector, six values per part. 
## Evaluation
- 2D. Projected COSEG
- 3D. ShapeNet
## Conclusion

## Notes

## References
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEwMjA4MTA2MzAsLTUxMDYxNTA1Niw3Mz
A5OTgxMTZdfQ==
-->